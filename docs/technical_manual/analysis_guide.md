# æ•°æ®åˆ†ææŒ‡å—

## ğŸ§® æ•°æ®åˆ†æå®Œæ•´æµç¨‹

### ğŸš€ å¿«é€Ÿå¼€å§‹

```bash
# è¿è¡Œè¶‹åŠ¿åˆ†æ
python scripts/trend_analysis.py --interval 4h --english

# ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
python scripts/trend_analysis.py --interval 4h --verbose
```

### ğŸ”§ åˆ†æé…ç½®

#### æ ¸å¿ƒå‚æ•°è®¾ç½®
æ–‡ä»¶ä½ç½®: `src/utils/config.py`

```python
# HMAå‚æ•°
HMA_PERIOD = 45                    # Hullç§»åŠ¨å¹³å‡å‘¨æœŸ
SLOPE_THRESHOLD = 0.001            # æ–œç‡é˜ˆå€¼

# è¶‹åŠ¿åˆ†æå‚æ•°
EVENT_WINDOW = 5                   # äº‹ä»¶çª—å£æœŸ
MIN_TREND_DURATION = 1             # æœ€å°è¶‹åŠ¿æŒç»­æ—¶é—´

# é£é™©æŒ‡æ ‡å‚æ•°
PFE_THRESHOLD = 5.0               # PFEé˜ˆå€¼
MAE_THRESHOLD = 3.0               # MAEé˜ˆå€¼
```

### ğŸ“Š åˆ†æç®—æ³•è¯¦è§£

#### 1. Hullç§»åŠ¨å¹³å‡(HMA)è®¡ç®—

```python
def calculate_hma(prices, period):
    """è®¡ç®—Hullç§»åŠ¨å¹³å‡"""
    # æ­¥éª¤1: è®¡ç®—åŠ æƒç§»åŠ¨å¹³å‡
    wma_half = prices.rolling(window=period//2).mean()
    wma_full = prices.rolling(window=period).mean()
    
    # æ­¥éª¤2: è®¡ç®—åŸå§‹HMA
    raw_hma = 2 * wma_half - wma_full
    
    # æ­¥éª¤3: å¹³æ»‘å¤„ç†
    hma = raw_hma.rolling(window=int(np.sqrt(period))).mean()
    
    return hma
```

#### 2. è¶‹åŠ¿è¯†åˆ«ç®—æ³•

```python
def identify_trends(df, hma_col='HMA_45'):
    """è¯†åˆ«è¶‹åŠ¿è½¬æ¢ç‚¹"""
    # è®¡ç®—HMAæ–œç‡
    df['HMA_slope'] = df[hma_col].diff()
    
    # è®¡ç®—æ–œç‡ç¬¦å·å˜åŒ–
    df['slope_sign'] = np.sign(df['HMA_slope'])
    df['slope_change'] = df['slope_sign'].diff().fillna(0)
    
    # è¯†åˆ«è¶‹åŠ¿è½¬æ¢ç‚¹
    df['turning_point'] = 0
    
    # ä¸Šæ¶¨è¶‹åŠ¿å¼€å§‹ï¼šæ–œç‡ç”±è´Ÿè½¬æ­£
    uptrend_start = df['slope_change'] == 2.0
    df.loc[uptrend_start, 'turning_point'] = 1
    
    # ä¸‹è·Œè¶‹åŠ¿å¼€å§‹ï¼šæ–œç‡ç”±æ­£è½¬è´Ÿ
    downtrend_start = df['slope_change'] == -2.0
    df.loc[downtrend_start, 'turning_point'] = -1
    
    return df
```

#### 3. PFE/MAEè®¡ç®—

```python
def calculate_pfe_mae(interval_data, trend_direction):
    """è®¡ç®—PFEå’ŒMAE"""
    start_price = interval_data['open'].iloc[0]
    high_price = interval_data['high'].max()
    low_price = interval_data['low'].min()
    
    if trend_direction == 'up':
        # ä¸Šæ¶¨è¶‹åŠ¿ï¼ˆåšå¤šç­–ç•¥ï¼‰
        pfe = (high_price / start_price - 1) * 100  # æœ€å¤§æ¶¨å¹…
        mae = (start_price / low_price - 1) * 100   # æœ€å¤§è·Œå¹…
    else:
        # ä¸‹è·Œè¶‹åŠ¿ï¼ˆåšç©ºç­–ç•¥ï¼‰
        pfe = (start_price / low_price - 1) * 100   # æœ€å¤§è·Œå¹…
        mae = (high_price / start_price - 1) * 100  # æœ€å¤§æ¶¨å¹…
    
    return pfe, mae
```

### ğŸ“ˆ åˆ†ææŒ‡æ ‡è¯´æ˜

#### æ ¸å¿ƒæŒ‡æ ‡

| æŒ‡æ ‡ | å«ä¹‰ | è®¡ç®—å…¬å¼ | ç­–ç•¥æ„ä¹‰ |
|------|------|----------|----------|
| **PFE** | æœ€å¤§æœ‰åˆ©åç§» | è¶‹åŠ¿æ–¹å‘æœ€å¤§ä»·æ ¼å˜åŒ– | ç†æƒ³æ”¶ç›Šæ½œåŠ› |
| **MAE** | æœ€å¤§ä¸åˆ©åç§» | åå‘æœ€å¤§ä»·æ ¼å˜åŒ– | æœ€å¤§é£é™©æŸå¤± |
| **Risk Ratio** | é£é™©æ”¶ç›Šæ¯” | MAE / PFE | é£é™©æ§åˆ¶æŒ‡æ ‡ |
| **Duration** | æŒç»­æ—¶é—´ | è¶‹åŠ¿åŒºé—´é•¿åº¦ | è¶‹åŠ¿ç¨³å®šæ€§ |

#### ç­–ç•¥æŒ‡æ ‡

| æŒ‡æ ‡ | å«ä¹‰ | è®¡ç®—æ–¹å¼ | åº”ç”¨åœºæ™¯ |
|------|------|----------|----------|
| **Ideal Profit** | ç†æƒ³æ”¶ç›Š | è¶‹åŠ¿æ–¹å‘æœ€å¤§æ”¶ç›Š | ç­–ç•¥æ”¶ç›Šè¯„ä¼° |
| **Actual Profit** | å®é™…æ”¶ç›Š | è¶‹åŠ¿ç»“æŸå‡€æ”¶ç›Š | å®é™…è¡¨ç°è¯„ä¼° |
| **Risk Loss** | é£é™©æŸå¤± | åå‘æœ€å¤§æŸå¤± | é£é™©æ§åˆ¶ |
| **Risk-Reward Ratio** | é£é™©æ”¶ç›Šæ¯” | é£é™©/æ”¶ç›Šæ¯”ç‡ | ç­–ç•¥ä¼˜åŒ– |

### ğŸ”„ åˆ†ææ‰§è¡Œæµç¨‹

#### æ­¥éª¤1: æ•°æ®é¢„å¤„ç†
```python
from src.analyzers.trend_analyzer import TrendAnalyzer

# åˆå§‹åŒ–åˆ†æå™¨
analyzer = TrendAnalyzer()

# åŠ è½½æ•°æ®
data = pd.read_parquet('src/utils/data/ETHUSDT_4h_processed_*.parquet')
```

#### æ­¥éª¤2: è¶‹åŠ¿è¯†åˆ«
```python
# è¯†åˆ«è½¬æŠ˜ç‚¹
turning_points = analyzer.identify_turning_points(data)

# åˆ†æè¶‹åŠ¿åŒºé—´
trend_intervals = analyzer.analyze_trend_intervals(data, turning_points)
```

#### æ­¥éª¤3: é£é™©åˆ†æ
```python
# è®¡ç®—PFE/MAE
pfe_mae_results = analyzer.calculate_pfe_mae(trend_intervals)

# é£é™©æ”¶ç›Šåˆ†æ
risk_analysis = analyzer.analyze_risk_reward(trend_intervals)
```

#### æ­¥éª¤4: ç­–ç•¥è¯„ä¼°
```python
# åšå¤šç­–ç•¥åˆ†æ
long_strategy = analyzer.analyze_uptrend_metrics(trend_intervals)

# åšç©ºç­–ç•¥åˆ†æ
short_strategy = analyzer.analyze_downtrend_metrics(trend_intervals)
```

### ğŸ“Š åˆ†æç»“æœè¾“å‡º

#### 1. JSONæŠ¥å‘Šæ ¼å¼
```json
{
    "analysis_summary": {
        "total_trends": 126,
        "uptrends": 63,
        "downtrends": 63,
        "high_risk_trends": 61
    },
    "uptrend_analysis": {
        "intervals": [...],
        "metrics": {...}
    },
    "downtrend_analysis": {
        "intervals": [...],
        "metrics": {...}
    }
}
```

#### 2. CSVæ•°æ®æ ¼å¼
```csv
trend_id,trend_type,start_time,end_time,start_price,end_price,price_change_pct,max_rally,max_decline,risk_ratio,is_risk_greater,duration_hours
TREND_001,ä¸‹é™è¶‹åŠ¿,2024-10-09 04:00:00,2024-10-09T12:00:00,2436.01,2461.30,1.04,1.48,0.53,2.79,True,8
```

### ğŸ¯ åˆ†æåº”ç”¨åœºæ™¯

#### 1. è¶‹åŠ¿è·Ÿè¸ªç­–ç•¥
```python
# è¯†åˆ«è¶‹åŠ¿è½¬æ¢ç‚¹
turning_points = analyzer.identify_turning_points(data)

# ç”Ÿæˆäº¤æ˜“ä¿¡å·
signals = analyzer.generate_trading_signals(turning_points)
```

#### 2. é£é™©ç®¡ç†
```python
# è®¡ç®—é£é™©æŒ‡æ ‡
risk_metrics = analyzer.calculate_risk_metrics(trend_intervals)

# è®¾ç½®æ­¢æŸç‚¹
stop_loss = analyzer.calculate_stop_loss(risk_metrics)
```

#### 3. ç­–ç•¥ä¼˜åŒ–
```python
# å‚æ•°ä¼˜åŒ–
best_params = analyzer.optimize_parameters(data, param_range)

# å›æµ‹åˆ†æ
backtest_results = analyzer.run_backtest(data, best_params)
```

### ğŸ” é«˜çº§åˆ†æåŠŸèƒ½

#### 1. äº‹ä»¶åˆ†æ
```python
# åˆ†æè½¬æŠ˜ç‚¹å‰åçš„äº‹ä»¶
event_analysis = analyzer.analyze_events(data, turning_points)

# äº‹ä»¶ç»Ÿè®¡
event_stats = analyzer.calculate_event_statistics(event_analysis)
```

#### 2. ç›¸å…³æ€§åˆ†æ
```python
# è¶‹åŠ¿ä¸å¸‚åœºæŒ‡æ ‡ç›¸å…³æ€§
correlation = analyzer.calculate_correlation(data, market_indicators)

# æ—¶é—´åºåˆ—ç›¸å…³æ€§
time_correlation = analyzer.calculate_time_correlation(data)
```

#### 3. é¢„æµ‹åˆ†æ
```python
# è¶‹åŠ¿é¢„æµ‹
trend_forecast = analyzer.forecast_trends(data, horizon=24)

# é£é™©é¢„æµ‹
risk_forecast = analyzer.forecast_risk(data, horizon=24)
```

### âš ï¸ åˆ†ææ³¨æ„äº‹é¡¹

#### 1. æ•°æ®è´¨é‡
- ç¡®ä¿æ•°æ®å®Œæ•´æ€§
- å¤„ç†å¼‚å¸¸å€¼å’Œç¼ºå¤±å€¼
- éªŒè¯æ—¶é—´åºåˆ—è¿ç»­æ€§

#### 2. å‚æ•°è°ƒä¼˜
- HMAå‘¨æœŸé€‰æ‹©
- æ–œç‡é˜ˆå€¼è®¾ç½®
- é£é™©å‚æ•°è°ƒæ•´

#### 3. ç»“æœéªŒè¯
- äº¤å‰éªŒè¯åˆ†æç»“æœ
- æ•æ„Ÿæ€§åˆ†æ
- ç¨³å¥æ€§æµ‹è¯•

### ğŸ› å¸¸è§é—®é¢˜

#### é—®é¢˜1: è¶‹åŠ¿è¯†åˆ«ä¸å‡†ç¡®
```python
# è§£å†³: è°ƒæ•´HMAå‚æ•°å’Œæ–œç‡é˜ˆå€¼
HMA_PERIOD = 30  # å‡å°å‘¨æœŸ
SLOPE_THRESHOLD = 0.005  # å¢å¤§é˜ˆå€¼
```

#### é—®é¢˜2: è®¡ç®—æ€§èƒ½é—®é¢˜
```python
# è§£å†³: ä¼˜åŒ–è®¡ç®—ç®—æ³•
# ä½¿ç”¨å‘é‡åŒ–æ“ä½œ
# åˆ†å—å¤„ç†å¤§æ•°æ®
# å¹¶è¡Œè®¡ç®—
```

#### é—®é¢˜3: å†…å­˜ä¸è¶³
```python
# è§£å†³: å†…å­˜ç®¡ç†
# åˆ†å—å¤„ç†æ•°æ®
# åŠæ—¶é‡Šæ”¾å†…å­˜
# ä½¿ç”¨é«˜æ•ˆæ•°æ®ç»“æ„
```

### ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

#### 1. ç®—æ³•ä¼˜åŒ–
```python
# ä½¿ç”¨NumPyå‘é‡åŒ–æ“ä½œ
def vectorized_calculation(data):
    return np.vectorize(calculation_function)(data)

# ä½¿ç”¨Pandaså†…ç½®å‡½æ•°
def pandas_optimized(data):
    return data.rolling(window=period).apply(calculation_function)
```

#### 2. å¹¶è¡Œè®¡ç®—
```python
# ä½¿ç”¨å¤šè¿›ç¨‹
from multiprocessing import Pool

def parallel_analysis(data_chunks):
    with Pool(processes=4) as pool:
        results = pool.map(analyze_chunk, data_chunks)
    return results
```

#### 3. å†…å­˜ä¼˜åŒ–
```python
# åˆ†å—å¤„ç†
def chunked_analysis(data, chunk_size=10000):
    for chunk in data.groupby(data.index // chunk_size):
        yield analyze_chunk(chunk)
```

---

*æœ€åæ›´æ–°: 2025-09-27*
*ç‰ˆæœ¬: v1.0.0*
